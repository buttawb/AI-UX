from django.shortcuts import render
from django.http import JsonResponse
from django.views.decorators.csrf import csrf_exempt
import json
import requests
from PIL import Image
from io import BytesIO
from google import genai
from google.genai import types
from openai import OpenAI

from ux_tester.gemini_keys import GLOBAL_SEARCH_API_KEY
from .views import FIGMA_TOKENS, OPENAI_API_KEY_SULTAN
import os
import base64

# Design iteration prompt template for Gemini
GEMINI_DESIGN_ITERATION_PROMPT = """You are a UX/UI design expert. Analyze the provided Figma screen and address the following UX issues:

{dropoff_points}

CRITICAL INSTRUCTIONS:
1. Focus on fixing the specific UX issues mentioned above
2. Maintain the overall design language and style
3. Keep all existing text exactly as is, with the same font, size, and position
4. Only modify elements that need improvement based on the UX issues
5. Ensure all changes improve usability while maintaining visual consistency
6. Do not add new text unless absolutely necessary to fix a UX issue
7. Maintain exact pixel-perfect alignment of all elements

Please provide an enhanced version of the design that addresses these UX issues while maintaining the original design's integrity."""


def design_iteration_view(request):
    """
    View function for the design iteration page.
    """
    # Get parameters from URL
    file_id = request.GET.get('file_id')
    token = request.GET.get('token')
    frame_id = request.GET.get('frame_id')
    dropoffs = request.GET.get('dropoffs')

    # Parse dropoffs if present
    dropoff_points = []
    if dropoffs:
        try:
            dropoff_points = json.loads(dropoffs)
        except:
            dropoff_points = []

    # Create context with pre-filled values
    context = {
        'file_id': file_id,
        'token': token,
        'frame_id': frame_id,
        'dropoff_points': dropoff_points
    }

    return render(request, 'design_iteration.html', context)


def generate_with_gemini(image, dropoff_points):
    """Generate design iteration using Gemini API"""
    # Initialize the Gemini client
    client = genai.Client(api_key=GLOBAL_SEARCH_API_KEY)

    # Format dropoff points for the prompt
    dropoff_text = "\n".join(
        [f"- {point.get('reason', '')}" for point in dropoff_points])

    # Create the prompt with dropoff points
    text_input = GEMINI_DESIGN_ITERATION_PROMPT.format(
        dropoff_points=dropoff_text)
    print(f"Original image mode: {image.mode}")

    # Convert image to RGB for optimal Gemini processing
    if image.mode in ['RGBA', 'LA']:
        # Create a white background
        background = Image.new('RGB', image.size, (255, 255, 255))
        # Paste the image on the background
        background.paste(image, mask=image.split()[-1])
        image = background
    elif image.mode != 'RGB':
        image = image.convert('RGB')

    print(f"Converted image mode: {image.mode}")

    # Save a high-quality version of the original for reference
    # reference_path = "static/generated_images/reference_design.png"
    # os.makedirs(os.path.dirname(reference_path), exist_ok=True)
    # image.save(reference_path, 'PNG', quality=100, optimize=False)

    response = client.models.generate_content(
        model="gemini-2.0-flash-exp",
        contents=["Give me a sample image of beatiful mobile chat design", image],
        config=types.GenerateContentConfig(
            response_modalities=['TEXT', 'IMAGE'],
        )
    )

    if response.candidates:
        # Handle both text and image responses
        text_response = ""
        image_response = None

        for part in response.candidates[0].content.parts:
            if part.text is not None:
                text_response += part.text
            elif part.inline_data is not None:
                # Convert the image data directly to a PIL Image
                image_response = Image.open(BytesIO(part.inline_data.data))

                # Ensure the generated image matches original dimensions
                if image_response.size != image.size:
                    image_response = image_response.resize(
                        image.size, Image.Resampling.LANCZOS)

                # Save the generated image with maximum quality
                output_path = "static/generated_images/generated_design.png"
                os.makedirs(os.path.dirname(output_path), exist_ok=True)
                image_response.save(output_path, 'PNG',
                                    quality=100, optimize=False)

        if not image_response:
            print("Warning: No image was generated by Gemini")

        return {
            "text": text_response,
            "image": image_response
        }
    return None


def generate_with_openai(image, dropoff_points):
    """Generate design iteration using OpenAI API"""
    # Initialize the OpenAI client with minimal configuration
    client = OpenAI(api_key=OPENAI_API_KEY_SULTAN)

    # Format dropoff points for the prompt
    dropoff_text = "\n".join(
        [f"- {point.get('reason', '')}" for point in dropoff_points])

    # Create the prompt with dropoff points
    text_input = GEMINI_DESIGN_ITERATION_PROMPT.format(
        dropoff_points=dropoff_text)

    # Ensure image is in highest quality and preserve text
    if image.mode != 'RGBA':
        image = image.convert('RGBA')

    # Convert image to base64
    buffered = BytesIO()
    image.save(buffered, format="PNG")
    img_str = base64.b64encode(buffered.getvalue()).decode()

    # First, analyze the image using vision model
    vision_messages = [
        {
            "role": "system",
            "content": "You are a UX/UI design expert. Your task is to analyze and improve designs based on UX issues."
        },
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": text_input
                },
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/png;base64,{img_str}",
                        "detail": "high"
                    }
                }
            ]
        }
    ]

    # Get analysis from vision model
    vision_response = client.chat.completions.create(
        model="gpt-4o",
        messages=vision_messages,
        max_tokens=4096
    )

    if not vision_response.choices:
        return None

    analysis = vision_response.choices[0].message.content

    # Now generate the improved image
    image_prompt = f"""Based on this UX analysis: {analysis}
    Generate an improved version of the design that addresses these UX issues while maintaining the original design's integrity.
    Keep all existing text exactly as is, with the same font, size, and position.
    Only modify elements that need improvement based on the UX issues.
    Ensure all changes improve usability while maintaining visual consistency."""

    # Generate the improved image
    response = client.responses.create(
        model="gpt-4.1-mini",
        input=image_prompt,
        tools=[{"type": "image_generation"}],
    )

    # Extract the generated image
    image_data = [
        output.result
        for output in response.output
        if output.type == "image_generation_call"
    ]

    if image_data:
        # Convert base64 to PIL Image
        image_bytes = base64.b64decode(image_data[0])
        generated_image = Image.open(BytesIO(image_bytes))

        # Ensure the generated image matches original dimensions
        if generated_image.size != image.size:
            generated_image = generated_image.resize(
                image.size, Image.Resampling.LANCZOS)

        # Save the generated image with maximum quality
        output_path = "static/generated_images/generated_design.png"
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        generated_image.save(output_path, 'PNG', quality=100, optimize=False)

        return {
            "text": analysis,
            "image": generated_image
        }

    return {
        "text": analysis,
        "image": None
    }


@csrf_exempt
def generate_iteration(request):
    """
    API endpoint to generate design iterations.
    """
    if request.method == 'POST':
        try:
            # Handle both JSON and form-data requests
            if request.content_type == 'application/json':
                data = json.loads(request.body)
            else:
                # Handle form-data
                data = {
                    'figma_token': request.POST.get('figma_token'),
                    'design_data': json.loads(request.POST.get('design_data', '{}')),
                    'dropoff_points': json.loads(request.POST.get('dropoff_points', '[]'))
                }

            figma_token = data.get('figma_token')
            design_data = data.get('design_data')
            dropoff_points = data.get('dropoff_points', [])

            if not figma_token:
                return JsonResponse({"error": "No access token provided"}, status=400)

            # Get the actual token value if it's a predefined token
            if figma_token in FIGMA_TOKENS:
                figma_token = FIGMA_TOKENS[figma_token]

            # Fetch Figma file data
            file_id = design_data.get('id')
            if not file_id:
                return JsonResponse({"error": "No Figma file ID provided"}, status=400)

            # Fetch Figma file structure
            figma_url = f"https://api.figma.com/v1/files/{file_id}"
            headers = {"X-Figma-Token": figma_token}
            figma_response = requests.get(figma_url, headers=headers)

            if figma_response.status_code != 200:
                return JsonResponse({"error": "Failed to fetch Figma file"}, status=400)

            figma_data = figma_response.json()

            # Extract frames and their images
            frames = []
            for canvas in figma_data.get('document', {}).get('children', []):
                for frame in canvas.get('children', []):
                    if frame.get('type') == 'FRAME':
                        frames.append({
                            'id': frame.get('id'),
                            'name': frame.get('name'),
                            'node': frame
                        })

            if not frames:
                return JsonResponse({"error": "No frames found in Figma file"}, status=400)

            # Take the first frame
            selected_frame = frames[0]

            # Fetch frame image with maximum quality (scale=4 for highest resolution)
            image_url = f"https://api.figma.com/v1/images/{file_id}?ids={selected_frame['id']}&format=png&scale=2"
            image_response = requests.get(image_url, headers=headers)

            if image_response.status_code != 200:
                return JsonResponse({"error": "Failed to fetch frame image"}, status=400)

            image_data = image_response.json().get('images', {})
            frame_image_url = image_data.get(selected_frame['id'])

            if not frame_image_url:
                return JsonResponse({"error": "Failed to get frame image URL"}, status=400)

            # Download and save the original image
            img_response = requests.get(frame_image_url)
            if img_response.status_code == 200:
                # Create PIL Image from the response content
                original_image = Image.open(BytesIO(img_response.content))

                # Save original image with maximum quality
                original_path = "static/generated_images/original_design.png"
                os.makedirs(os.path.dirname(original_path), exist_ok=True)
                original_image.save(original_path, 'PNG',
                                    quality=100, optimize=False)

                # Generate iteration using Gemini
                response = generate_with_gemini(original_image, dropoff_points)
                # response = generate_with_openai(original_image, dropoff_points)

                if response:
                    # Parse the text response as JSON
                    try:
                        text_data = json.loads(response['text'])
                    except json.JSONDecodeError:
                        text_data = {
                            "improved_design": {
                                "description": response['text'],
                                "key_changes": [response['text']]
                            }
                        }

                    # Convert original image to base64
                    with open(original_path, 'rb') as img_file:
                        original_base64 = base64.b64encode(
                            img_file.read()).decode('utf-8')

                    # Convert generated image to base64
                    generated_path = "static/generated_images/generated_design.png"
                    with open(generated_path, 'rb') as img_file:
                        generated_base64 = base64.b64encode(
                            img_file.read()).decode('utf-8')

                    return JsonResponse({
                        'status': 'success',
                        'data': {
                            'original_images': [{
                                'name': selected_frame['name'],
                                'image': original_base64
                            }],
                            'improved_design': {
                                'description': text_data.get('improved_design', {}).get('description', ''),
                                'key_changes': text_data.get('improved_design', {}).get('key_changes', []),
                                'image': generated_base64
                            }
                        }
                    })

            return JsonResponse({
                'status': 'error',
                'message': 'Failed to generate iteration'
            }, status=500)

        except Exception as e:
            print(f"Error in generate_iteration: {str(e)}")
            import traceback
            print(f"Traceback: {traceback.format_exc()}")
            return JsonResponse({
                'status': 'error',
                'message': f'An unexpected error occurred: {str(e)}'
            }, status=500)

    return JsonResponse({
        'status': 'error',
        'message': 'Method not allowed'
    }, status=405)
